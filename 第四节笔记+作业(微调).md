



# 1. 笔记

### 1. 为什么要微调

1. foundation 大语言模型 在能够实现“普遍的”“一般性的”任务的“通用”，需要进行预训练。
2. 若想利用通用基座模型到自己下游业务场景中，若没有经过专属微调，直接拿来用的话，其实表现不如领域内已专门训练好的模型。 

### 2. 两种fine tune 范式
![image](https://github.com/bubblefu/InternLM_Camp_md/assets/70378994/f0505f42-095c-4be5-8493-64016bbdac3a)

1. **增量预训练**
   1. 基座模型（直接从hugging face下载的模型），让他学习一些<u>**新的知识**</u>
      1. 例子：我的垂直领域的一些常识
      2. 文章、书籍、代码等
   2. 不需要一问一答的学习，而是有监督、有标注的
   3. 例子：<u>世界上第一高峰是珠穆朗玛</u>       ---只是一句话而已
2.  **指令跟随微调**
   1. 场景：让模型学会对话模板，根据人类的指令进行对话，让模型输出更符合人类喜好偏好的回答
   2. 训练数据：高质量的对话和问答数据
   3. 需要很高质量的标注（问答对）
   4. 例子：<u>问：世界上第一高峰是什么？ 答：是珠穆朗玛峰啊</u>          --是格式严格的问答句
3. **用肺癌的例子：增量预训练和指令微调有什么区别？**
   1. 对于无指令微调的LLM，当问它，什么是肺癌时，LLM可能不会觉得这是个问句，即不会觉得我在问它问题！！！
      1. 只是单纯的拟合训练数据中的空间分布
      2. 它意识不到你是在想问它什么
   2. 进行指令微调，输入了一对一的聊天数据后
      1. 意识到了这是个问话，是人在向他问问题
      2. 就会回答肺癌是什么。

<img src="https://github.com/bubblefu/InternLM_Camp_md/assets/70378994/ae79ada9-b337-455a-9052-0a690365264a" alt="image" style="zoom:50%;" />

### 3. 数据的一生

<img src="https://github.com/bubblefu/InternLM_Camp_md/assets/70378994/66ead99f-a822-4c53-84cb-1298e6ada30d" alt="image" style="zoom:33%;" />

1. 原始数据：收集来的还不符合LLM训练格式的原始数据，比如一条文本（我是大傻子，你是谁）

2. 标准格式数据：
   
   1. 将原始数据清洗和整理成标准格式。确保数据一致性，并去除噪音数据，例如错别字、重复对话等。标准格式通常包括对话的输入和输出部分。
      1. 数据清洗：去除多余的空格、特殊字符等。
      2. 数据整理：确保每条对话记录都有明确的**起点和终点**。
   2. json格式，有以下字段**（xtuner中）**
      1. system角色
      2. user
      3. assistant
   
3. 添加对话模板：

   1. 定义：对话模板是一种<u>**预定义的格式**</u>，可以帮助模型理解对话的结构

   2. 目的1：让LLM能区分出system、user、assistant三个字段

   3. 目的2：让LLM知道什么时候开始一段对话、什么时候结束一段对话

   4. 模板具体组成：字段+起始符号+结束符号

      1. 每个模型对字段和起始结束符号的定义不同
      2. 不同厂家推出的模型又不同的模板

      <img src="https://github.com/bubblefu/InternLM_Camp_md/assets/70378994/6087316a-8224-4580-afe9-bbeafa2421c0" alt="image" style="zoom:25%;" />

      <img src="https://github.com/bubblefu/InternLM_Camp_md/assets/70378994/7b329e4e-fb33-4aa5-a5a1-903cb559a03e" alt="image" style="zoom: 50%;" />

4. tokenized数据

   1. 定义：对标准格式的数据进行分词（tokenization）处理。分词是将文本转换为模型可识别的token序列，这一步通常依赖于预训练模型的词表（vocabulary）。

5. 添加label

   1. 添加标签信息，通常是对话的目标输出

6. 开始训练：将tokenized数据和标签输入到模型中

   1. 喂给模型的是如下图右侧组装后的数据（以LM为例）
      1. <|System|>   你是一个安全的AI助手
      2. <|User|>   世界最高峰是什么峰
      3. <|Bot|>  珠穆朗玛峰

<img src="https://github.com/bubblefu/InternLM_Camp_md/assets/70378994/fdbd8e72-0ec4-4dd0-a8b7-d6eae8c1c8a5" alt="image" style="zoom: 67%;" />

7. 训练时，xtuner已经打包好了，一键训练即可



### 4. XTuner 微调原理

1. 想改造大模型，对大模型中某些部分进行改动，而不是全量改动。就像整容。

2. XTuner使用LoRA 和 QLoRA两种微调方案：整容手术刀

3. LoRA原理：

   1. 在原本LLM的linear旁，新增一个旁路分支——包含两个连续的小linear，新增的支路通常叫做adapter

      1. adapter：参数量远远小于原本的linear

      2. 能大幅度降低训练显存消耗

         <img src="https://github.com/bubblefu/InternLM_Camp_md/assets/70378994/615ea2c5-e046-472d-bd66-fb738bbd8030" alt="image" style="zoom:50%;" />



4. 全参数微调   vs  LoRA  vs QLoRA
   1. full finetuning：
      1. LLM和adapter(优化器)都要加载到显存中
      2. LLM参与训练并更新参数
      3. 需要保存base model中参数的优化器状态
   2. LoRA：
      1. LLM 加载到显存中，adapter参数优化器的LoRA部分加载到显存中，其他部分不需要！！
      2. LLM只参与forward；backward时只有Adapter部分更新参数 
   3. QLoRA：
      1. LLM加载到显存中，利用4bit量化的方式加载——不太精确地 四舍五入地加载，又节省了显存开销
      2. 其他与lora类似

<img src="https://github.com/bubblefu/InternLM_Camp_md/assets/70378994/83456a35-36fa-4df9-961e-8169570fe2d5" alt="image" style="zoom:67%;" />

### 5. xtuner微调框架

1. 特点：
   1. 傻瓜式操作
   2. 配置文件形式封装微调场景——方便
   3. 轻量级——对于7B参数LLM，最小只需要8G显存就可以
2. 架构图
![image](https://github.com/bubblefu/InternLM_Camp_md/assets/70378994/0841a450-f87d-42af-909e-1cf1e4545283)

# 2. 实战

![image](https://github.com/bubblefu/InternLM_Camp_md/assets/70378994/2d86cada-8d6d-4eca-bc95-90f8ed17d75a)

# 3. 微调的一些小技巧


Tip 1:Start withaSmall Model(从小模型开始，测试是否一切正常)

Tip 2: Use LoRA or OLoRA(使用 LoRA 或 OLoRA)

Tip 3: Create 10 manual questions(手动创建 10 个问题，测试是否一切正常)

Tip 4: Create datasets manually(手动创建数据集，会有更深的理解)

Tip 5: Start training withjust 100 rows(从只有 100 行开始训练，测试模型是否正常)

Tip 6: Always create a validation data split(始终创建验证数据集)

Tip 7: Start by only training on one GPU(开始时只使用一个GPU进行训练)

Tip 8: Use weights and biases for logging(记录日志)Scale up rows,tuning type,then modelsize(前面都没问题的话)

Tip 9: Consider unsupervised fine-tuning if you've lots ofdata(如果数据量很大，可以考虑无监督微调)

Tip 10: Use preference fine-tuning(ORPO)(尝试使用偏好微调(ORPO))
