# 1. 视频笔记
## 1. 关于RAG
对于询问大模型中没有的内容时，由于没有学习过，大模型会不知道或者胡乱编造答案。对此，传统的做法是去采集新增语料，通过微调的方式，对模型进行续训。
这种传统做法现实中会出现问题
  1. 知识更新太快
  2. 语料库太大，训练成本高
  3. 难以收集等

针对这种现象，RAG技术可以很好解决————没有额外训练的情况下，能回答不在知识库的问题了。 怎么实现的呢？——————了解RAG

**RAG**  Retrieval augmented generation
1. 定义：检索增项生成模型
2. 通过结果检索和生成的过程 ， 增强了语言模型在解锁特定问题的性能。这个过程涉及从外部知识源检索相关信息，并将这些信息用于指导语言模型生成更准确更丰富的回答。
3. 更通俗的说：RAG就是一个**搜索引擎**————用户输入的内容作为索引————外部知识库中搜寻相关内容————结合LLM的能力生成回答
4. 最大优势：解决LLM在处理知识密集型任务时可能遇到的挑战。提供更准确的回答、降低成本、实现外部记忆————————没有训练过程，就是检索，成本很低
5. RAG应用：问答系统、文本生成、信息检索、图片描述
6. **RAG工作原理**：
   1. 索引 indexing ：处理外部知识——把知识源 （文档、网页）分割成chunk，编码成向量，存储在Vector-DB中。
   2. 检索 Retrieval: 负责接收用户问题，接收到后也编码成向量，在vectorDB中找到与之最相关的文档块。
   3. 生成 Generation: 将检索到的文档块与原始问题一起作为提示，输入到LLM中，生成回答。
   4. ![image](https://github.com/bubblefu/InternLM_Camp_md/assets/70378994/b2e5fc67-102f-44d7-815c-2480517380e2)
7. **向量数据库  Vector DB**
   1. 是RAG中，专门储存外部数据的地方。
   2. 数据存储：将文本及其他数据通过预训练的模型转换为固定长度的向量表示，这些向量能够很好捕捉文本的语义信息。
   3. 相似性检索：根据用户的查询向量，使向量数据库快速找出最相关的向量的过程。
      1. 用余弦相似度或者其他相似度方式来完成。
      2. 根据score进行排序，最相关的文档将被用于后续文本生成。
   4. 向量表示的优化：使用更高级的文本编码技术，句子嵌入或段落嵌入；对数据库进行优化以支持大规模向量搜索；包括尝试不同的嵌入方法；
      1. 直接影响RAG的好坏
8. **RAG的发展历程**
   1. native RAG : 即上述RAG 流程
   2. advanced RAG ：在native RAG的基础上，在检索和生成模块有诸多改进：（摘要生成、内容推荐等应用）
      1. pre-retrieval optimization：比如句子窗口检索
      2. post-retrieval optimization：比如对结果进行重排
      3. hybrid search combining different retrieval methods：混合搜索结合不同检索方法
   4. modular RAG：强调灵活性和模块化。允许集成不同组件和技术以适应特定任务或需求。它更加明确地区分检索和生成阶段，使得可以针对每个部分使用专门的模型和技术。（多模态任务，对话系统等应用）
9. **RAG常见优化方法**
    1. 提升数据库质量
      1. 嵌入式优化  embedding optimization
         1. 考虑通过结果稀疏编码器、密集检索器以及多任务的方式增强嵌入的性能
      2. 索引优化  indexing optimization
         1. 增加数据粒度、优化索引结构、添加metadata、对齐优化和混合检索等策略来提升索引质量
    2. 前检索、后检索（检索之前和之后）
       1. 查询扩展和转换：时的用户原始问题更清晰、更适合检索任务
          1. 采用多查询方法，通过LLM的prompt engineer来扩展查询
       2. 上下文管理：
## 2. 关于茴香豆
# 2. 实际操作
