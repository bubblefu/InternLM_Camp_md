# 1.视频笔记

1. 专用模型——通用大模型
   1. 专用：针对特定任务，一个模型解决一个问题
      1. **问1：怎么实现？是仅仅是参数不同么**
   2. 通用：一个模型对应多种任务，多种模态。文本——文本的任务，一个模型就可以解决
      1. **问2：什么是模态**
2. 书生浦语大模型
   1. 2023.7——present
   2. 2024.1   第二代开源
   3. 体系：
      1. 7B轻量级模型（base——模型基座 、LM2、  chat）
      2. 20B综合模型（base——模型基座 、LM2、  chat）

<img src="https://zpyldebou9.feishu.cn/space/api/box/stream/download/asynccode/?code=NTE3NzFmM2ExNmZjMWE4YzM2Zjc2ODJkYThiMmJhNzFfdHo2OGtJTGNMQm5CRTd4WlplWFY3UnpxbU1Fb3NFeGlfVG9rZW46U3h6TWJFTE82bzl1NnF4T0dXcmNYTVJxblJlXzE3MTc2NTgwNjY6MTcxNzY2MTY2Nl9WNA" alt="img" style="zoom:50%;" />

1. internLM2：
   1. 专注于构建高 质量语料，让模型有更好的建模能力——用结构化语言回答问题
      1. 扮演计划助手
      2. 充满人文关怀的对话
      3. 有想象力创作
   2. 能调用工具，调用工具能力升级——可处理更复杂的问题 ，获取最新知识
   3. 数据分析功能，主要是根据Python的一些matplotlib和可视化模块。甚至有机器学习调用
   4. 内生计算能力
      1. 100以内数学运算接近100%准确率、 1000以内的 80%左右准确率
      2. 复杂数学运算和求解
      3. 可配备代码解释器，在特定数学评测集GSM8K和MATH上，效果更佳
         1. MATH 上 ，模型计算能力 + 解释器   精度32.5——>51.2  大于在GPT4的表现  
      4. 大模型计算能力不太可靠
         1. **问3：为什么这么说？为什么100以内准确率还不能达到100%？是不是大模型本身的特点**
         2. 
2. 从模型——应用
   1. 根据不同业务场景，进行模型选型，看一下社区的不同开源模型在经典评测集和榜单上的评测效果，选一个或者几个。
   2. 同时去考虑业务场景是否复杂，若复杂，需要对模型进行微调
   3. 此时考虑算力是否足够 。若算力充足，可以微调全参数；若有限，只能调部分参数
   4. 进行微调后，模型具备了业务场景相关知识。
   5. 此时再去评估模型是否需要和环境做交互，或者是否需要和一些API做交互。
   6. 若需要，则去构建智能体。
   7. 然后在实际业务场景里，对模型进行评测；
   8. 若通过评测，对模型进行部署应用

每一步都需要代码开发和选择工具。

**问4：是否一定要按这个顺序，比如我可以先看一下算力够不够，再去寻思别的事**

<img src="https://github.com/bubblefu/InternLM_Camp_md/blob/main/images/image-20240606151531237.png" alt="image-20240606151531237" style="zoom:33%;" />

1. 书生浦语全链路体系
   1. 数据——预训练——微调——部署——评测——应用
   2. 每一个链路都有开源APP（广义）提供
   3. 数据：（opendatalab获取）
      1. 万卷1.0
         1. 文本数据 ：5亿    1TB
         2. 图像-文本数据集：2200万+文件   140GB
         3. 视频数据集：2200万+文件    140GB
         4. 多模态、精细化、对齐了价值观、并都经过了数据清洗
      2. 万卷CC
         1. 2013-2023年互联网公开内容
         2. 已对有毒、色情和个人隐私等安全方面进行处理
         3. 来源更多
   4. 预训练
      1. 问5：什么是8卡，什么是千卡训练？是指的显卡么？
      2. 预训练框架兼容性：接入hugging face等生态
      3. 优化技术：hybrid zero技术
   5. 微调
      1. Xturner框架
         1. 适配不同生态（hugging face模型、 modelscope等）
         2. 自动优化加速：20系列显卡+就可以用   |   显存有优化   | 加速细节有优化  
         3. 8GB显存就能调7B模型
      2. 下游应用中：常用两种
         1. 增量续训
            1. 通过预训练，让模型学到新的知识
         2. 有监督微调
            1. 目的：让模型学会理解各种指令进行对话
            2. 注入少量**领域**知识  to  训练出高质量的对话和问答数据——可能更针对于特定场景
         3. 注：引入的参数少，微调成本也会下降
   6. OpenCompass 2.0   评测体系
      1. 提供compassRank 大语言模型 和多模态模型 榜单，  实时、中立、权威
      2. compassKit ：  评测依赖的工具  开源了。   支持超过100个数据集的评测、数据污染检查、长文本能力评测、双语主观评测
      3. compassHub：评测开源社区——希望更好的建立大模型评测基准，让大家参与进来
      4. 评测趋势和分析
         1. GPT4 turbo最牛逼，别的综合只能接近。
         2. 复杂推理：国内模型和GPT4比差距还是比较大 
         3. 文科和语言维度时，效果和模型尺寸差别不大；但是理科和推理、代码等维度，效果和尺寸强相关！！！
         4. 中文场景下，国内大模型和GPT4差别不大了，某个角度甚至会胜出。
         5. **问：什么是循环评测策略？别的评测体系也是用这种策略么？**
      5. 国内大模型对中文场景有性能优势
   7. 部署：
      1. 部署指的是：如何把模型在GPU上更快跑起来，并在性能和显存上进行更好的优化，发表了LMDeploy的全流程解决方案。
         1. 接口是用Python，gRPC  ，RESTful
         2. 引擎有pytorch，为啥没有TF？
         3. 推理性能上，LMDeploy 在很多模型上是优秀于LLM的
         4. 指标：RPS  requests per second
   8. 智能体   Lagent
      1. 是自己开发的轻量级的智能体框架 
      2. 支持其他智能体：react  rewoo autoGPT，可以一键支持，也可以重新开发
      3. 支持多种大语言模型
      4. 工具箱：**AgentLego** 

# 2. QA

##### 1. 专用大模型如何实现一个模型解决一个问题？







##### 2. 什么是多模态？

就是输入的数据，是来自不同类型的source。  比如文本、语音、图像数据，都可以同时作为input source被一个模型处理。     而这些类型都是被称为不同的感知模态。

##### 3. **为什么这个说法：大模型的计算能力不太可靠？为什么100以内准确率还不能达到100%？是不是大模型本身的特点？**





##### 4. 从模型——应用是否一定要按这个顺序？

从大模型到应用的过程包括模型选型、微调、算力考虑、业务场景知识整合、与环境和API交互的构建、实际业务场景评测以及最终的部署与应用。

肯定不是，比如如果我公司的算力已知就是一般，还想做个什么事，那就得优先考虑模型选型能不能满足自己的算力。

##### 5.**什么是循环评测策略？**

就是多轮评测，根据第一轮test的结果去调参和调整其他指标，重新训练，然后再test。多轮。