# 1. 配置开发机环境

## 1. 步骤

### 1. 创建开发机

① 创建开发机<img src="https://github.com/bubblefu/InternLM_Camp_md/blob/main/images/image-20240606104149757.png" alt="image-20240606104149757" style="zoom:25%;" />

② 输入名称（自选）

③ 选择Cuda11.7 conda 镜像

④ 选择10%或30%的A100资源

<img src="https://github.com/bubblefu/InternLM_Camp_md/blob/main/images/image-20240606103922151.png" alt="image-20240606103922151" style="zoom:20%;" />

⑤ 选择运行时长 

⑥ 立即创建

<img src="https://github.com/bubblefu/InternLM_Camp_md/blob/main/images/image-20240606103940695.png" alt="image-20240606103940695" style="zoom:20%;" />

### 2. 使用开发机

1. 点击进入开发机——jupyterlab——终端，在终端里进行操作

   <img src="https://github.com/bubblefu/InternLM_Camp_md/blob/main/images/image-20240606104506292.png" alt="image-20240606104506292" style="zoom:25%;" />

2. 点击进入开发机——直接使用终端操作

3. 点击SSH连接， remote在自己电脑里用自己电脑的terminal来操作。这样可以不用网页。

   <img src="https://github.com/bubblefu/InternLM_Camp_md/blob/main/images/image-20240606104551920.png" alt="image-20240606104551920" style="zoom:50%;" /><img src="https://github.com/bubblefu/InternLM_Camp_md/blob/main/images/image-20240606104629384.png" alt="image-20240606104629384" style="zoom:50%;" />

### 3. 配置环境

1. 一键配置 studio-conda -o internlm-base -t demo
   1. 注：推荐这种方式，可以直接重置conda环境，如果你玩坏了，没有conda环境了，会重新装一个。  
   2. 注：在开发机里自己没法装conda环境，只能用装好的或者studio-conda来安装的。

2. 配置成功后会出现：

   ![image-20240606105110365](https://github.com/bubblefu/InternLM_Camp_md/blob/main/images/image-20240606105110365.png)时间大概30-45分钟。 <u>若没成功，请参考debug小节。</u>

   

## 2. debug及总结

在安装开发机并配置环境时，开发机的配置选择 和 空间占用 都会导致studio-conda 命令后最终 配置环境失败。

#### 1. 常见error 1：  studio-conda 不成功

1. ```
   InvalidArchiveError("Error with archive /root/.conda/pkgs/pip-24. 0-py310h06a4308 0. conda.You probably need to delete and re-download or re-create this file.Message was:\n\nfailedrrno 2]No such file or directory:/root/.conda/pkgs/pip-24.0-py310h06a4308 0. conda’")
   
   InvalidArchiveError("Error with archive /root/.conda/pkgs/openssl-1. 1.1w-h7f8727e 0. conda.You probably need to delete and re-download or re-create this file.Message was:\n\nfaileErrno 2No such file or directory:/root/,conda/pkgs/openssl-1.1. 1w-h7f8727e 0. conda ")
   
   
   初始化 conda环境: demo 失败 
   
   ```

出现这个问题的原因是： **<u>云盘空间没有给分配。是0</u>**。 正常会分配100G的空间给你。你可以查看下开发机控制台——我的云盘——右侧——空间容量：

如果是：那就是正常的![image-20240606111331267](https://github.com/bubblefu/InternLM_Camp_md/blob/main/images/image-20240606111331267.png)



如果是：就需要找助教开空间 ![image-20240606111410844](https://github.com/bubblefu/InternLM_Camp_md/blob/main/images/image-20240606111410844.png)

注：这个问题  容易被忽略！！  血的教训┭┮﹏┭┮



#### 2. 常见error2： conda 环境不好用了

参考QA文档，问题1，玩坏了环境后该怎么办？

即：只能重新构建开发机环境了。   conda环境没有办法自己装，只能用默认的。

#### 3. 总结

基于我的debug路径，我总结出开发机配置环境的原理：

studio-conda  安装是如何安装？

1. ~/share/文件夹里保存所有配置环境需要的packages。
2. 我们自己的conda环境在~/.conda/文件中
3. 安装过程：不断copy-paste  即从   ~/share/pkgs/     —>    ~/.conda/pkgs/ 

4. 因为：
   1. share文件夹在开发机的云服务器总机中，通过软链接能让我们在自己的终端中看到这个文件夹。     
   2. 给我们分配的100G内容，使我们自己的开发机的存储空间，在studio-conda前，就是空的。   随着安装，即安装和复制粘贴packages到我们自己空间中后，我们才能用这些模块进行模型部署。
5. 所以如果没有分配空间，不可能安装成功的。

# 2. 模型实战

## 1. 基本模型**`InternLM2-Chat-1.8B`**

### 1. 基本步骤

1. demo环境已经配置完成，进入环境中：
		conda activate demo
	
2. 安装后续的包
        pip install huggingface-hub==0.17.3
        pip install transformers==4.34 
        pip install psutil==5.9.8
        pip install accelerate==0.24.1
        pip install streamlit==1.32.2 
        pip install matplotlib==3.8.3 
        pip install modelscope==1.9.5
        pip install sentencepiece==0.1.99
    
3. 进行chat-1.8B模型的下载：
        mkdir -p /root/demo
        touch /root/demo/cli_demo.py
        touch /root/demo/download_mini.py
        cd /root/demo
    
    ![image-20240606112752476](https://github.com/bubblefu/InternLM_Camp_md/blob/main/images/image-20240606112752476.png)
    
4. 配置download_mini.py

    <img src="https://github.com/bubblefu/InternLM_Camp_md/blob/main/images/image-20240606112925150.png" alt="image-20240606112925150" style="zoom:25%;" />

5. 配置cli_demo.py

   <img src="https://github.com/bubblefu/InternLM_Camp_md/blob/main/images/image-20240606113005774.png" alt="image-20240606113005774" style="zoom: 25%;" />

6. ```
   python /root/demo/download_mini.py 进行模型下载
   ```

    ![image-20240606113110879](https://github.com/bubblefu/InternLM_Camp_md/blob/main/images/image-20240606113110879.png)

7. 下载成功后运行demo

   ```
   python /root/demo/cli_demo.py
   ```

8. 出现user>>> 后，可以输入内容与之对话

<img src="https://github.com/bubblefu/InternLM_Camp_md/blob/main/images/image-20240606113245786.png" alt="image-20240606113245786" style="zoom:33%;" /><img src="https://github.com/bubblefu/InternLM_Camp_md/blob/main/images/image-20240606113249370.png" alt="image-20240606113249370" style="zoom:33%;" />

### 2. 总结：

	1. 1.8B大模型在文字、语文、创作方面的反馈还可以。
	2. 1.8B大模型在数字计算方面的理解一般。  比如 1+1等于几，会等于2；如果问1+1 = ？  ，模型会不理解这种问的意思。
	3. 数学计算呈一定范围：65535 + 256 可以直接给出答案；655350+356就可能得不出答案了。
	4. 1.8B大模型没有记忆功能。
	5. 模型下载和加载很慢。但看B站视频还是蛮快的。



## 2. 八戒

### 1. 基本步骤

1. 下载八戒的demo：在demo环境中，下载分支，进入到目录

   ```
   cd /root/   # 进入到root中
   git clone https://gitee.com/InternLM/Tutorial -b camp2
   # 这条命令会克隆远程仓库 https://gitee.com/InternLM/Tutorial，并且会切换到名为 camp2 的分支，而不是默认的主分支
   
   cd /Tutorial/
   ```

2. 运行分支中的下载.py 并运行chat文件

   ```
   python /root/Tutorial/helloworld/bajie_download.py
   
   streamlit run /root/Tutorial/helloworld/bajie_chat.py --server.address 127.0.0.1 --server.port 6006
   # 运行 bajie_chat.py 这个 Streamlit 应用，并将其绑定到本地主机的 6006 端口上。即可以通过在浏览器中访问 http://127.0.0.1:6006 来查看和交互这个 Streamlit 应用。
   ```

<img src="https://github.com/bubblefu/InternLM_Camp_md/blob/main/images/image-20240606093323758.png" alt="image-20240606093323758" style="zoom: 33%;" />

<img src="https://github.com/bubblefu/InternLM_Camp_md/blob/main/images/image-20240606093440008.png" alt="image-20240606093440008" style="zoom:33%;" />

<img src="https://github.com/bubblefu/InternLM_Camp_md/blob/main/images/image-20240606093452301.png" alt="image-20240606093452301" style="zoom:33%;" />

<img src="https://github.com/bubblefu/InternLM_Camp_md/blob/main/images/image-20240606094056368.png" alt="image-20240606094056368" style="zoom:33%;" />

3. 待程序运行的同时，对端口环境配置本地 PowerShell。在powershell里，运行一个ssh命令：
   1. <u>通过 SSH 建立一个隧道，将本地机器的 `6006` 端口转发到远程服务器 `ssh.intern-ai.org.cn` 上的 `6006` 端口。在访问本地的 `127.0.0.1:6006` 时，实际上是在访问远程服务器的 `127.0.0.1:6006` 端口。这个设置通常用于安全地访问远程服务器上的 web 服务，比如Streamlit 应用</u>

```
ssh -CNg -L 6006:127.0.0.1:6006 root@ssh.intern-ai.org.cn -p 我的端口号

# 端口号在开发机SSH登录中找到，一定是我自己的，因为要登录开发机服务器。
# -CNg 中， -C 是 SSH连接压缩功能，加快速度
            N 是 告诉 SSH 不要执行远程命令，只进行端口转发。这个选项用于只建立隧道，而不打开远程终端。
           -g 是 允许远程主机连接到本地转发端口。这意味着除了本地机器，其他机器也可以通过本地机器的 IP 地址和端口号访问转发的端口。

# -L 6006:127.0.0.1:6006: 进行本地端口转发
```

<img src="https://github.com/bubblefu/InternLM_Camp_md/blob/main/images/image-20240606094132553.png" alt="image-20240606094132553" style="zoom:33%;" />

4. 现在可以打开http://127.0.0.1:6006了。 会弹出网页，是八戒demo的对话网页。

<img src="https://github.com/bubblefu/InternLM_Camp_md/blob/main/images/image-20240606094237443.png" alt="image-20240606094237443" style="zoom:33%;" />![image-20240606094256654](https://github.com/bubblefu/InternLM_Camp_md/blob/main/images/image-20240606094256654.png)

![image-20240606094341045](https://github.com/bubblefu/InternLM_Camp_md/blob/main/images/image-20240606094341045.png)

<img src="https://github.com/bubblefu/InternLM_Camp_md/blob/main/images/image-20240606094607401.png" alt="image-20240606094607401" />

![image-20240606094944972](https://github.com/bubblefu/InternLM_Camp_md/blob/main/images/image-20240606094944972.png)

### 2. 使用总结

1. 我觉得八戒做的很好，特别是文字回答的调控上。
2. 反馈速度还是比较慢。

## 3. Lagent Demo
### 1. lagent学习
#### 1. Lagent流程图解读
对于下图，其实我不是很懂，我找了些资料，用我自己的语言，去描述一下lagent的架构。
```
① Human Feedback/Instruction/Observations → LLM模块：人类提供的反馈、指示和观察输入给LLM模块，帮助其理解任务。
② LLM模块 → Planning & Action 模块：LLM模块生成指令，传递给Planning & Action模块进行规划和行动决策。
③ Planning & Action 模块 → Action Executor：规划好的行动传递给Action Executor模块执行。
④ Action Executor → LLM模块：执行结果返回给LLM模块，可能影响下一步的指令生成。
```
#### 2. 主要模块
1. Action Executor：执行各种具体操作。它接受来自不同模块的输入，并根据这些输入执行相应的动作。
2. LLM模块：核心，用于理解和生成自然语言。它接受来自人类的反馈和指示，以及来自其他模块的输入，生成相应的输出。
3. Planning & Action 模块：负责规划和执行动作。它使用不同的策略和迭代方法来确定最合适的行动方案。

#### 3. 各个模块
1. python executor: 执行python代码的模块，处理编程任务、计算和数据处理，是action executor的一个input source。
2. Search、Calculator、Calendar等等，都是特定功能模块。同样作为Action Executor的输入源，提供特定任务的解决方案。
3. Plan-Act Iteration：不断迭代规划和执行，直到任务完成。
4. Plan-Then-Act：先进行全面的规划，然后再执行计划。
5. Reflection：对已执行的动作进行反思和总结，优化未来的行动策略。
6. Exploration：探索新的可能性和解决方案。
### 2. 登录lagent页面操作
1. 操作步骤：
```
# 下载lagent，安装环境
conda activate demo && cd /root/demo
git clone https://gitee.com/internlm/lagent.git 
git checkout 581d9fb8987a5d9b72bb9ebd37a95efd47d479ac     # 检查包完整性
pip install -e . # 源码安装  -e 标志告诉 pip 使用“editable”模式安装

# 运行lagent ，利用streamlit包来快速构建web环境，并run起来
cd /root/demo/lagent
ln -s /root/share/new_models/Shanghai_AI_Laboratory/internlm2-chat-7b /root/models/internlm2-chat-7b     # 使 /root/models/internlm2-chat-7b 与原始模型目录保持同步，从而便于访问和管理 。符号链接可以让您在一个位置管理数据或文件，同时在另一个位置引用它们，而无需复制文件或数据。
修改 Python代码，主要是选择7B模型，如下图。
streamlit run /root/demo/lagent/examples/internlm2_agent_web_demo_hf.py --server.address 127.0.0.1 --server.port 6006    
powershell中，利用ssh连接
ssh -CNg -L 6006:127.0.0.1:6006 root@ssh.intern-ai.org.cn -p 38374
点击 http://127.0.0.1:6006
```
3. 相关截图：
![image](https://github.com/bubblefu/InternLM_Camp_md/assets/70378994/2c2fbe57-6157-4788-8d64-a105d39dbff5)
![image](https://github.com/bubblefu/InternLM_Camp_md/assets/70378994/2cc6e121-fbeb-4e32-b7dc-e0081a82dc1b)
![image](https://github.com/bubblefu/InternLM_Camp_md/assets/70378994/29cc61cb-7e97-4e64-ac82-12a0a47079fb)
![image](https://github.com/bubblefu/InternLM_Camp_md/assets/70378994/f4ae5d28-6507-4cb2-85a1-578804d84e1a)
![image](https://github.com/bubblefu/InternLM_Camp_md/assets/70378994/7d14d315-9b01-44aa-a618-875362651b74)
![image](https://github.com/bubblefu/InternLM_Camp_md/assets/70378994/e94dabba-7061-49e5-bdf9-3a5c3c6e8ad1)

### 3. 使用lagent一些心得
1. 观察1
   1. 在lagent里，在利用数据处理库（numpy等）产生答案前，可能会产生5秒左右的计算耗时，甚至会10秒+。
   2. 自己的计算过程会出错，会纠错、即提出新的思路去给出答案，但少数时间会不断地循环给出错误方案————可能是模型本身计算能力的问题，7B还是不够。
   3. 若关掉数据分析tool， 对于简单数学问题，也会给出方案。但不会利用写代码的方式。

2. 观察2
   1. lagent会根据问题，自己调用package去写代码，但他会报错：若conda环境里没有安装这个package；同时它不会自己安装。
   2. 安装package后，就可以根据问题自己去利用合适的package给出答案，说明7B规模模型通过Lagent构建智能体已经能够完成一些工具使用的任务。
![image](https://github.com/bubblefu/InternLM_Camp_md/assets/70378994/f662e339-94ae-4569-86f3-9043ae29d4aa)
![image](https://github.com/bubblefu/InternLM_Camp_md/assets/70378994/16b24336-87bc-462b-acbf-b9866b57f4ed)
![image](https://github.com/bubblefu/InternLM_Camp_md/assets/70378994/31548e4f-fb59-466c-8525-408564799143)

## 4. 浦语 灵笔







<img src="https://github.com/bubblefu/InternLM_Camp_md/blob/main/images/image-20240606093323758.png" alt="image-20240606093323758" style="zoom: 33%;" />

<img src="https://github.com/bubblefu/InternLM_Camp_md/blob/main/images/image-20240606093440008.png" alt="image-20240606093440008" style="zoom:33%;" />

<img src="https://github.com/bubblefu/InternLM_Camp_md/blob/main/images/image-20240606093452301.png" alt="image-20240606093452301" style="zoom:33%;" />

<img src="https://github.com/bubblefu/InternLM_Camp_md/blob/main/images/image-20240606094056368.png" alt="image-20240606094056368" style="zoom:33%;" />

<img src="https://github.com/bubblefu/InternLM_Camp_md/blob/main/images/image-20240606094132553.png" alt="image-20240606094132553" style="zoom:33%;" />

<img src="https://github.com/bubblefu/InternLM_Camp_md/blob/main/images/image-20240606094237443.png" alt="image-20240606094237443" style="zoom:33%;" />![image-20240606094256654](https://github.com/bubblefu/InternLM_Camp_md/blob/main/images/image-20240606094256654.png)

![image-20240606094341045](https://github.com/bubblefu/InternLM_Camp_md/blob/main/images/image-20240606094341045.png)

<img src="https://github.com/bubblefu/InternLM_Camp_md/blob/main/images/image-20240606094607401.png" alt="image-20240606094607401" />

![image-20240606094944972](https://github.com/bubblefu/InternLM_Camp_md/blob/main/images/image-20240606094944972.png)

5. 使用总结：

![image-20240606150304820](C:\Users\chai\AppData\Roaming\Typora\typora-user-images\image-20240606150304820.png)
